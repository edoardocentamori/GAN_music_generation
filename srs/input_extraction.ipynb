{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token(song, token, begin):\n",
    "    token_shape = list(song.shape)\n",
    "    token_shape[0] = 1\n",
    "    tens_tokens = np.ones(token_shape) * token\n",
    "    if begin == True:\n",
    "        return np.concatenate((tens_tokens, song), axis = 0)\n",
    "    else:\n",
    "        return np.concatenate((song, tens_tokens), axis = 0) \n",
    "    \n",
    "def standardize_song(song, lenght):\n",
    "    if(song.shape[0]>lenght):\n",
    "        return song\n",
    "    song_shape = list(song.shape)\n",
    "    song_shape[0] = lenght - song_shape[0]\n",
    "    song = np.concatenate((song, np.zeros(song_shape)), axis=0)\n",
    "    assert song.shape[0] == lenght\n",
    "    return song\n",
    "\n",
    "def song_transform(song, max_lenght):\n",
    "    song = song[:max_lenght]\n",
    "    song = np.pad(song, 0, 'constant')\n",
    "    song = add_token(song, 1, begin=True)\n",
    "    song = add_token(song, -1, begin=False)\n",
    "    song = standardize_song(song, max_lenght+2)    \n",
    "    return song\n",
    "\n",
    "def batch_uniform(song_batch, max_lenght):\n",
    "    return torch.from_numpy(np.stack([song_transform(song, max_lenght) for song in song_batch], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongIterator():\n",
    "    def __init__(self, song_list, batch_size, song_size, shuffle):\n",
    "        self.step = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.song_size = song_size\n",
    "        if shuffle == True:\n",
    "            self.internal_song_list = random.sample(list(song_list),len(list(song_list)))\n",
    "        else:\n",
    "            self.internal_song_list = list(song_list)\n",
    "                    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        self.step += 1\n",
    "        if self.step > 1000:\n",
    "            raise StopIteration\n",
    "        if (self.step + 1)  * self.batch_size < len(self.internal_song_list):\n",
    "            batch = self.internal_song_list[(self.step * self.batch_size):((self.step + 1) * self.batch_size)]\n",
    "        elif self.step  * self.batch_size < len(self.internal_song_list):\n",
    "            batch = self.internal_song_list[(self.step * self.batch_size):]\n",
    "        else:\n",
    "            raise StopIteration\n",
    "        return batch_uniform(batch, self.song_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(os.path.join(pathlib.Path(globals()['_dh'][0]).parent, \"data\"), \"js-fakes-16thSeparated.npz\")\n",
    "jsf = np.load(input_path, allow_pickle=True, encoding='latin1')\n",
    "\n",
    "max_song_length = np.asarray([len(song) for song in jsf['pitches']]).max()\n",
    "\n",
    "#song_iterator = SongIterator(song_list=jsf['pitches'], batch_size=64, song_size=max_song_length)\n",
    "\n",
    "# test iterator -> Now working\n",
    "# for epoch in range(3):\n",
    "#     for i, batch_song in enumerate(SongIterator(song_list=jsf['pitches'], batch_size=64, song_size=max_song_length, shuffle=True)):\n",
    "#         print(\"Epoch = {}, step = {}, input type = {}, input shape = {}\".format(epoch, i, type(batch_song), batch_song.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, num_heads_1, num_heads_2, bs, emb_notes, emb_f):\n",
    "        super(TransformerBlock, self).__init__() # Seq, batch, features\n",
    "        self.ln1 = nn.LayerNorm([bs * num_heads_2 * emb_notes, num_heads_1 * emb_f]) #layer norm: [L, bs, Emb_f, Emb_notes] -> [L, bs, Emb_f, Emb_notes]\n",
    "        self.mha_f = nn.MultiheadAttention(num_heads_1 * emb_f, num_heads_1, dropout=0.25) # multi-head attention per features: [L, BS * Emb_notes, Emb_f] -> [L, BS * Emb_notes, Emb_f]\n",
    "        self.ln2 = nn.LayerNorm([bs * num_heads_1 * emb_f, num_heads_2 * emb_notes]) #layer norm: [BS, L, Emb_f, Emb_notes] -> [BS, L, Emb_f, Emb_notes]\n",
    "        self.mha_l = nn.MultiheadAttention(num_heads_2 * emb_notes, num_heads_2, dropout=0.25) # multi-head attention per lunghezza: [BS * Emb_f, L, Emb_notes] -> [BS * Emb_f, L, Emb_notes]\n",
    "        self.ln3 = nn.LayerNorm([bs, num_heads_1 * emb_f, num_heads_2 * emb_notes]) #layer norm\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_heads_2 * emb_notes, num_heads_2 * emb_notes),  # Linear transformation\n",
    "            nn.LayerNorm([bs, num_heads_1 * emb_f, num_heads_2 * emb_notes]),  # Layer normalization\n",
    "            nn.ELU(),  # Activation function (ELU)\n",
    "            nn.Linear(num_heads_2 * emb_notes, num_heads_2 * emb_notes)  # Linear transformation\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x): # add various reshape\n",
    "        #[L, bs, Emb_f, Emb_notes]\n",
    "        #print(\"Step 1, x shape = {}\".format(x.shape))\n",
    "        x_1 = x.transpose(2, 3).reshape((x.shape[0], x.shape[1] * x.shape[3], x.shape[2])) \n",
    "        #[L, BS * Emb_notes, Emb_f]\n",
    "        #print(\"Step 2, x_1 shape = {}\".format(x_1.shape))\n",
    "        norm_x_1 = self.ln1(x_1) \n",
    "        #print(\"Step 3, x_1 shape = {}\".format(x_1.shape))\n",
    "        attn_output_1 = self.mha_f(norm_x_1, norm_x_1, norm_x_1)[0] # [0] selects the attention output, to be decided if padding is needed\n",
    "        #print(\"Step 4, attn_output_1 shape = {}\".format(attn_output_1.shape))\n",
    "        x_2 = x_1 + attn_output_1 # residual connection\n",
    "        #print(\"Step 4, x_2 shape = {}\".format(x_2.shape))\n",
    "        x_2 = x_2.reshape(x.shape[0], x.shape[1], x.shape[3], x.shape[2]).transpose(2,3).reshape(x.shape[0], x.shape[1] * x.shape[2], x.shape[3])\n",
    "        #[L, BS * Emb_f, Emb_notes]\n",
    "        #print(\"Step 5, x_2 shape = {}\".format(x_2.shape))\n",
    "        norm_x_2 = self.ln2(x_2)\n",
    "        #print(\"Step 6, x_norm_x_2 shape = {}\".format(norm_x_2.shape))\n",
    "        attn_output_2 = self.mha_l(norm_x_2, norm_x_2, norm_x_2)[0] # [0] selects the attention output, to be decided if padding is needed\n",
    "        #print(\"Step 7, attn_output_2 shape = {}\".format(attn_output_2.shape))\n",
    "        x = x + attn_output_2.reshape(x.shape)\n",
    "        #print(\"Step 8, x shape = {}\".format(x.shape))\n",
    "        x = self.ln3(x)\n",
    "        #print(\"Step 9, x shape = {}\".format(x.shape))\n",
    "        x = self.mlp(x)\n",
    "        #print(\"Step 9, x shape = {}\".format(x.shape))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "emb_notes = 32 \n",
    "emb_f = 4\n",
    "L = 150\n",
    "num_heads_1 = 4\n",
    "num_heads_2 = 4\n",
    "trans_block = TransformerBlock(num_heads_1 = num_heads_1, num_heads_2 = num_heads_2, bs = bs, emb_notes = emb_notes, emb_f = emb_f)\n",
    "#[L, bs, Emb_f, Emb_notes]\n",
    "\n",
    "rand_input = torch.rand((L, bs, num_heads_1 * emb_f, num_heads_2 * emb_notes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_song = torch.randint(36,82,(L, bs, 4))\n",
    "tokens = [0, 1, -1, -2] + list(range(36,82)) # 0: padding, 1: start of signal, -1: end of signal, -2: unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator might relize that padding = real example, find out how to avoid this -> Thus add an attenction mask for padding\n",
    "\n",
    "#Discriminator -> Some Transformer block followed by taking the first token + linear + tanh\n",
    "\n",
    "# Create a tranform operation that remove extra symbol, add \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
