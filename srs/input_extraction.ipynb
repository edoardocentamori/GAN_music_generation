{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token(song, token, begin):\n",
    "    token_shape = list(song.shape)\n",
    "    token_shape[0] = 1\n",
    "    tens_tokens = np.ones(token_shape) * token\n",
    "    if begin == True:\n",
    "        return np.concatenate((tens_tokens, song), axis = 0)\n",
    "    else:\n",
    "        return np.concatenate((song, tens_tokens), axis = 0) \n",
    "    \n",
    "def standardize_song(song, lenght):\n",
    "    if(song.shape[0]>lenght):\n",
    "        return song\n",
    "    song_shape = list(song.shape)\n",
    "    song_shape[0] = lenght - song_shape[0]\n",
    "    song = np.concatenate((song, np.zeros(song_shape)), axis=0)\n",
    "    assert song.shape[0] == lenght\n",
    "    return song\n",
    "\n",
    "def song_transform(song, max_lenght):\n",
    "    song = song[:max_lenght]\n",
    "    song += np.ones_like(song)*np.arange(song.shape[-1])*100\n",
    "    song = np.pad(song, 0, 'constant')\n",
    "    song = add_token(song, 1, begin=True)\n",
    "    song = add_token(song, -1, begin=False)\n",
    "    song = standardize_song(song, max_lenght+2)    \n",
    "    return song\n",
    "\n",
    "def batch_uniform(song_batch, max_lenght):\n",
    "    return torch.from_numpy(np.stack([song_transform(song, max_lenght) for song in song_batch], axis=0))\n",
    "\n",
    "\n",
    "def rand_song_generation(L_distribution, bs, max_lenght):    \n",
    "    songs_batch = []\n",
    "    for _ in range(bs):\n",
    "        L = np.random.choice(L_distribution)\n",
    "        songs_batch.append(song_transform(np.random.randint(36,82,(L, 4)),max_lenght))\n",
    "    return batch_uniform(songs_batch, max_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongIterator():\n",
    "    def __init__(self, song_list, batch_size, song_size, shuffle):\n",
    "        self.step = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.song_size = song_size\n",
    "        if shuffle == True:\n",
    "            self.internal_song_list = random.sample(list(song_list),len(list(song_list)))\n",
    "        else:\n",
    "            self.internal_song_list = list(song_list)\n",
    "                    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        self.step += 1\n",
    "        if self.step > 1000:\n",
    "            raise StopIteration\n",
    "        if (self.step + 1)  * self.batch_size < len(self.internal_song_list):\n",
    "            batch = self.internal_song_list[(self.step * self.batch_size):((self.step + 1) * self.batch_size)]\n",
    "        elif self.step  * self.batch_size < len(self.internal_song_list):\n",
    "            batch = self.internal_song_list[(self.step * self.batch_size):]\n",
    "        else:\n",
    "            raise StopIteration\n",
    "        return batch_uniform(batch, self.song_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract real data\n",
    "\n",
    "input_path = os.path.join(os.path.join(pathlib.Path(globals()['_dh'][0]).parent, \"data\"), \"js-fakes-16thSeparated.npz\")\n",
    "jsf = np.load(input_path, allow_pickle=True, encoding='latin1')\n",
    "len_seq = np.asarray([len(song) for song in jsf['pitches']])\n",
    "\n",
    "max_song_length = len_seq.max()\n",
    "\n",
    "#song_iterator = SongIterator(song_list=jsf['pitches'], batch_size=64, song_size=max_song_length)\n",
    "\n",
    "# test iterator -> Now working\n",
    "# for epoch in range(3):\n",
    "#     for i, batch_song in enumerate(SongIterator(song_list=jsf['pitches'], batch_size=64, song_size=max_song_length, shuffle=True)):\n",
    "#         print(\"Epoch = {}, step = {}, input type = {}, input shape = {}\".format(epoch, i, type(batch_song), batch_song.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing real and fake batch song generation\n",
    "real_batch_song = next(SongIterator(song_list=jsf['pitches'], batch_size=64, song_size=max_song_length, shuffle=True))\n",
    "fake_batch_song = rand_song_generation(len_seq, 64, max_song_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add key_padding_mask\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, num_heads_1, num_heads_2, bs, emb_notes, emb_f):\n",
    "        super(TransformerBlock, self).__init__() # Seq, batch, features\n",
    "        self.ln1 = nn.LayerNorm([bs * num_heads_2 * emb_notes, num_heads_1 * emb_f]) #layer norm: [L, bs, Emb_f, Emb_notes] -> [L, bs, Emb_f, Emb_notes]\n",
    "        self.mha_f = nn.MultiheadAttention(num_heads_1 * emb_f, num_heads_1, dropout=0.25) # multi-head attention per features: [L, BS * Emb_notes, Emb_f] -> [L, BS * Emb_notes, Emb_f]\n",
    "        self.ln2 = nn.LayerNorm([bs * num_heads_1 * emb_f, num_heads_2 * emb_notes]) #layer norm: [BS, L, Emb_f, Emb_notes] -> [BS, L, Emb_f, Emb_notes]\n",
    "        self.mha_l = nn.MultiheadAttention(num_heads_2 * emb_notes, num_heads_2, dropout=0.25) # multi-head attention per lunghezza: [BS * Emb_f, L, Emb_notes] -> [BS * Emb_f, L, Emb_notes]\n",
    "        self.ln3 = nn.LayerNorm([bs, num_heads_1 * emb_f, num_heads_2 * emb_notes]) #layer norm\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_heads_2 * emb_notes, num_heads_2 * emb_notes),  # Linear transformation\n",
    "            nn.LayerNorm([bs, num_heads_1 * emb_f, num_heads_2 * emb_notes]),  # Layer normalization\n",
    "            nn.ELU(),  # Activation function (ELU)\n",
    "            nn.Linear(num_heads_2 * emb_notes, num_heads_2 * emb_notes)  # Linear transformation\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x): # add various reshape\n",
    "        #[L, bs, Emb_f, Emb_notes]\n",
    "        #print(\"Step 1, x shape = {}\".format(x.shape))\n",
    "        x_1 = x.transpose(2, 3).reshape((x.shape[0], x.shape[1] * x.shape[3], x.shape[2])) \n",
    "        #[L, BS * Emb_notes, Emb_f]\n",
    "        #print(\"Step 2, x_1 shape = {}\".format(x_1.shape))\n",
    "        norm_x_1 = self.ln1(x_1) \n",
    "        #print(\"Step 3, x_1 shape = {}\".format(x_1.shape))\n",
    "        attn_output_1 = self.mha_f(norm_x_1, norm_x_1, norm_x_1)[0] # [0] selects the attention output, to be decided if padding is needed\n",
    "        #print(\"Step 4, attn_output_1 shape = {}\".format(attn_output_1.shape))\n",
    "        x_2 = x_1 + attn_output_1 # residual connection\n",
    "        #print(\"Step 4, x_2 shape = {}\".format(x_2.shape))\n",
    "        x_2 = x_2.reshape(x.shape[0], x.shape[1], x.shape[3], x.shape[2]).transpose(2,3).reshape(x.shape[0], x.shape[1] * x.shape[2], x.shape[3])\n",
    "        #[L, BS * Emb_f, Emb_notes]\n",
    "        #print(\"Step 5, x_2 shape = {}\".format(x_2.shape))\n",
    "        norm_x_2 = self.ln2(x_2)\n",
    "        #print(\"Step 6, x_norm_x_2 shape = {}\".format(norm_x_2.shape))\n",
    "        attn_output_2 = self.mha_l(norm_x_2, norm_x_2, norm_x_2)[0] # [0] selects the attention output, to be decided if padding is needed\n",
    "        #print(\"Step 7, attn_output_2 shape = {}\".format(attn_output_2.shape))\n",
    "        x_3 = x + attn_output_2.reshape(x.shape)\n",
    "        #print(\"Step 8, x shape = {}\".format(x.shape))\n",
    "        x_3 = self.ln3(x_3)\n",
    "        #print(\"Step 9, x shape = {}\".format(x.shape))\n",
    "        x_3 = self.mlp(x_3)\n",
    "        #print(\"Step 9, x shape = {}\".format(x.shape))\n",
    "        return x_3 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4, 16, 128])\n",
      "torch.Size([150, 4, 16, 128])\n"
     ]
    }
   ],
   "source": [
    "# Test TransformerBlock -> Work\n",
    "bs = 4\n",
    "emb_notes = 32 \n",
    "emb_f = 4\n",
    "L = 150\n",
    "num_heads_1 = 4\n",
    "num_heads_2 = 4\n",
    "trans_block = TransformerBlock(num_heads_1 = num_heads_1, num_heads_2 = num_heads_2, bs = bs, emb_notes = emb_notes, emb_f = emb_f)\n",
    "#[L, bs, Emb_f, Emb_notes]\n",
    "\n",
    "rand_input = torch.rand((L, bs, num_heads_1 * emb_f, num_heads_2 * emb_notes))\n",
    "print(rand_input.shape)\n",
    "print(trans_block(rand_input).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(SinusoidalPosEmb, self).__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        position_enc = np.array([[pos / np.power(10000, 2*i/self.dim) for i in range(self.dim)] \n",
    "                                 if pos != 0 else np.zeros(self.dim) for pos in range(x.shape[0])])\n",
    "        # keep dim 0 for padding token position encoding zero vector # To be decided what to do with this\n",
    "        position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
    "        position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
    "        position_enc = np.expand_dims(position_enc, axis=(1,2))\n",
    "        position_enc = np.repeat(position_enc, repeats=x.shape[1], axis=1)\n",
    "        position_enc = np.repeat(position_enc, repeats=x.shape[2], axis=2)\n",
    "        return torch.from_numpy(position_enc).type(torch.FloatTensor)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_layers, num_emb, num_heads_1, emb_f, num_heads_2, emb_notes, bs):\n",
    "        super(Generator, self).__init__()\n",
    "        #[L, bs, Emb_f, notes]\n",
    "        self.embedding = nn.Embedding(num_emb, num_heads_1 * emb_f) # To be refined\n",
    "        self.embedding.weight.data = 0.001 * self.embedding.weight.data # Unclear\n",
    "        #[L, bs, Emb_f, num_heads_1 * emb_f]\n",
    "        self.pos_emb = SinusoidalPosEmb(num_heads_2 * emb_notes)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(num_heads_1, num_heads_2, bs, emb_notes, emb_f) for _ in range(num_layers)])\n",
    "        self.fc_out = nn.Linear(num_heads_2 * emb_notes, num_heads_2 * emb_notes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Gen Step 1, x shape = {}\".format(x.shape))\n",
    "        input_emb = self.embedding(x)\n",
    "        print(\"Gen Step 2, input_emb shape = {}\".format(input_emb.shape))\n",
    "        pos_emb = self.pos_emb(x)\n",
    "        print(\"Gen Step 3, pos_emb shape = {}\".format(pos_emb.shape))\n",
    "        emb = input_emb + pos_emb\n",
    "        print(\"Gen Step 4, emb shape = {}\".format(emb.shape))\n",
    "        for block in self.blocks:\n",
    "            emb = block(emb) # add key_padding_mask\n",
    "            print(\"Gen Step 5 loop, emb shape = {}\".format(emb.shape))\n",
    "        return emb\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S soprano (100), A alto (200), T tenor (300), B bass (400). \n",
    "\n",
    "n_tokens = len([0, 1, -1, -2]) + 4 * len(range(36,82)) \n",
    "tokens = [0, 1, -1, -2] + list(range(36,82)) # 0: padding, 1: start of signal, -1: end of signal, -2: unknown\n",
    "batch_song = next(SongIterator(song_list=jsf['pitches'], batch_size=64, song_size=max_song_length, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.7893, -1.0900, -0.7382,  ...,  0.3927, -0.0835, -1.1346],\n",
       "        [ 1.2599,  0.3797,  0.1331,  ...,  0.5523, -0.5993, -0.2147],\n",
       "        [ 0.9429,  0.1292, -0.7234,  ...,  0.0361,  0.8884,  0.1994],\n",
       "        ...,\n",
       "        [ 1.7880,  0.0824,  1.4844,  ..., -0.5106,  0.2426,  1.2985],\n",
       "        [-0.0824, -0.8936, -0.4848,  ..., -0.5941, -1.3363,  0.8541],\n",
       "        [ 1.1477, -0.5253,  1.3606,  ..., -1.4152,  0.8251, -0.3641]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that Generator work as expected \n",
    "num_layers = 3\n",
    "num_emb = 10 # to be adjusted  \n",
    "#Gen = Generator(num_layers, n_tokens, num_heads_1, emb_f, num_heads_2, emb_notes, bs)\n",
    "noise_input = rand_song_generation(len_seq, bs, max_song_length)\n",
    "#Gen(noise_input.type(torch.int32))\n",
    "\n",
    "\n",
    "test_embedding = nn.Embedding(n_tokens, num_heads_1 * emb_f) # To be refined\n",
    "test_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator might relize that padding = real example, find out how to avoid this -> Thus add an attenction mask for padding\n",
    "\n",
    "#Discriminator -> Some Transformer block followed by taking the first token + linear + tanh\n",
    "\n",
    "# Create a tranform operation that remove extra symbol, add "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
